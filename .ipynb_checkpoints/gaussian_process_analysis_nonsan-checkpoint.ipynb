{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "from scipy import stats\n",
    "\n",
    "from MLP.mlp_regression import mlp_regression, model_validation, mlp_prediction, mlp_prediction_error, mlp_train_graph, errorDist, mlp_train_multi_graph, mlp_train_multi_graph_comb, mlp_train_multi_3dgraph_comb\n",
    "from MLP.utils import combineArray, multiArraySort, data_loader_from_csv, data_loader_pathloss, describeData, data_loader_pathloss_with_freq\n",
    "\n",
    "pd.set_option('display.max_rows', 999)\n",
    "pd.set_option('precision', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "from scipy import stats\n",
    "\n",
    "from MLP.mlp_regression import mlp_regression, model_validation, mlp_prediction, mlp_prediction_error, mlp_train_graph, errorDist, mlp_train_multi_graph, mlp_train_multi_graph_comb, mlp_train_multi_3dgraph_comb\n",
    "from MLP.utils import data_loader_pathloss, describeData, data_loader_pathloss_with_freq\n",
    "from GMM.utils import gp_train_multi_3dgraph, gp_ann_train_multi_3dgraph, gpCompareDiffDim, mergeSet\n",
    "\n",
    "pd.set_option('display.max_rows', 999)\n",
    "pd.set_option('precision', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114545\n",
      "13456\n",
      "Covariance Matrix\n",
      "           dist      ploss   height\n",
      "dist    0.37188    5.98064  0.00204\n",
      "ploss   5.98064  167.97724  0.03692\n",
      "height  0.00204    0.03692  0.00043\n",
      "--------------------------------------------------\n",
      "Preprocessing <data/PLdata_nonsan_wt_400.csv>...Total 13456\n",
      "- moving type: total: 10458 (training: 8366/validation: 2092)\n",
      "- stationary type: total: 2998 (training: 2398/validation: 600)\n",
      "===============================================================================\n",
      "114455\n",
      "13406\n",
      "Covariance Matrix\n",
      "           dist      ploss   height\n",
      "dist    0.36645    6.68311  0.00201\n",
      "ploss   6.68311  203.15810  0.04374\n",
      "height  0.00201    0.04374  0.00043\n",
      "--------------------------------------------------\n",
      "Preprocessing <data/PLdata_nonsan_wt_1399.csv>...Total 13406\n",
      "- moving type: total: 10408 (training: 8326/validation: 2082)\n",
      "- stationary type: total: 2998 (training: 2398/validation: 600)\n",
      "===============================================================================\n",
      "114341\n",
      "13339\n",
      "Covariance Matrix\n",
      "           dist      ploss   height\n",
      "dist    0.35902    6.51480  0.00197\n",
      "ploss   6.51480  198.41971  0.03838\n",
      "height  0.00197    0.03838  0.00043\n",
      "--------------------------------------------------\n",
      "Preprocessing <data/PLdata_nonsan_wt_2249.csv>...Total 13339\n",
      "- moving type: total: 10341 (training: 8272/validation: 2069)\n",
      "- stationary type: total: 2998 (training: 2398/validation: 600)\n",
      "===============================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.01619317, 2.60205999],\n",
       "       [2.01670472, 2.60205999],\n",
       "       [2.01796877, 2.60205999],\n",
       "       ...,\n",
       "       [3.36165588, 2.60205999],\n",
       "       [3.36166415, 2.60205999],\n",
       "       [3.36170707, 2.60205999]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%autoreload\n",
    "X_train_m_400, X_val_m_400, y_train_m_400, y_val_m_400, X_train_s_400, X_val_s_400, y_train_s_400, y_val_s_400 = data_loader_from_csv('data/PLdata_nonsan_wt_400.csv', np.log10(400), 'dist' ,2.3, testRatio=0.8)\n",
    "X_train_m_1399, X_val_m_1399, y_train_m_1399, y_val_m_1399, X_train_s_1399, X_val_s_1399, y_train_s_1399, y_val_s_1399 = data_loader_from_csv('data/PLdata_nonsan_wt_1399.csv', np.log10(1399),'dist', 2.3, testRatio=0.8)\n",
    "X_train_m_2249, X_val_m_2249, y_train_m_2249, y_val_m_2249, X_train_s_2249, X_val_s_2249, y_train_s_2249, y_val_s_2249 = data_loader_from_csv('data/PLdata_nonsan_wt_2249.csv', np.log10(2249),'dist', 2.3, testRatio=0.8)\n",
    "\n",
    "X_train_m = combineArray(X_train_m_400, X_train_m_1399, X_train_m_2249)\n",
    "y_train_m = combineArray(y_train_m_400, y_train_m_1399, y_train_m_2249)\n",
    "X_val_m = combineArray(X_val_m_400, X_val_m_1399, X_val_m_2249)\n",
    "y_val_m = combineArray(y_val_m_400, y_val_m_1399, y_val_m_2249)\n",
    "\n",
    "X_train_s = combineArray(X_train_s_400, X_train_s_1399, X_train_s_2249)\n",
    "y_train_s = combineArray(y_train_s_400, y_train_s_1399, y_train_s_2249)\n",
    "X_val_s = combineArray(X_val_s_400, X_val_s_1399, X_val_s_2249)\n",
    "y_val_s = combineArray(y_val_s_400, y_val_s_1399, y_val_s_2249)\n",
    "\n",
    "X_train_m_400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "dataX_m = list()\n",
    "dataY_m = list()\n",
    "dataX_m.append(X_train_m_400)\n",
    "dataY_m.append(y_train_m_400)\n",
    "dataX_m.append(X_train_m_1399)\n",
    "dataY_m.append(y_train_m_1399)\n",
    "dataX_m.append(X_train_m_2249)\n",
    "dataY_m.append(y_train_m_2249)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train_m\n",
    "y = y_train_m\n",
    "\n",
    "# Instantiate a Gaussian Process model\n",
    "# kernel = C(1.0, (1e-3, 1e3)) * RBF(10, (1e-2, 1e2))\n",
    "# kernel = 1.0 * RBF(length_scale=100.0, length_scale_bounds=(1e-2, 1e3)) \\\n",
    "#    + WhiteKernel(noise_level=1, noise_level_bounds=(1e-10, 1e+1))\n",
    "# gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9)\n",
    "kernel = 1.0 * RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e3)) \\\n",
    "    + WhiteKernel(noise_level=1e-5, noise_level_bounds=(1e-10, 1e+1))\n",
    "gp_ma = GaussianProcessRegressor(kernel=kernel,\n",
    "                              alpha=0.0)\n",
    "# Fit to data using Maximum Likelihood Estimation of the parameters\n",
    "gp_ma.fit(X, y)\n",
    "\n",
    "filename = 'model/gp_nonsan_wt_3d_model.sav'\n",
    "pickle.dump(gp_ma, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "model = None\n",
    "model = pickle.load(open('model/gp_nonsan_wt_3d_model.sav', 'rb'))\n",
    "\n",
    "print(\"<Nonsan - Winter> Gaussian Process (dist<=2300m)\")\n",
    "mlp_train_multi_3dgraph_comb(model, dataX_m, dataY_m, X_train_m, ['0.4', '1.399','2.249'])\n",
    "\n",
    "print(model.loss_)\n",
    "print(model.n_iter_ )\n",
    "print(model.n_layers_)\n",
    "print(model.n_outputs_)\n",
    "stat = np.array([mlp_prediction_error(model,X_train_m_400, y_train_m_400),mlp_prediction_error(model,X_val_m_400, y_val_m_400),\n",
    "                 mlp_prediction_error(model,X_train_m_1399, y_train_m_1399),mlp_prediction_error(model,X_val_m_1399, y_val_m_1399),\n",
    "                 mlp_prediction_error(model,X_train_m_2249, y_train_m_2249),mlp_prediction_error(model,X_val_m_2249, y_val_m_2249),\n",
    "                 mlp_prediction_error(model,X_train_m, y_train_m), mlp_prediction_error(model,X_val_m, y_val_m)])\n",
    "\n",
    "(pd.DataFrame(stat.reshape((4,2)),index=pd.Index(['0.4Ghz','1.399Ghz','2.249Ghz', 'Overall']), columns=pd.Index(['train error','val error'],name='RMSE(dB)')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
