{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from equationmodel_ann import ann_mlp_regression, prediction_rmse_error, ann_linear_compare_graph\n",
    "from util import ADD_data_loader, combineDF, filteringDF, getFreeSpacePathLoss, makeXforGraphWithGroupingFrequency,\\\n",
    "                makeXforGraph, inverseScale, samplingData, normalizeData,train_2d_graph, train_3d_graph\n",
    "\n",
    "desired_width=620\n",
    "pd.set_option('display.width', desired_width)\n",
    "pd.set_option('display.max_columns',30)\n",
    "pd.options.display.float_format = \"{:.2f}\".format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADD data preprocessing\n",
      "../data/PLdata_paju_wt_400.csv: distance filtering(before):(110440, 4)\n",
      "../data/PLdata_paju_wt_400.csv: distance filtering(after):(22532, 4)\n",
      "../data/PLdata_paju_wt_2249.csv: distance filtering(before):(110246, 4)\n",
      "../data/PLdata_paju_wt_2249.csv: distance filtering(after):(22505, 4)\n",
      "../data/PLdata_paju_wt_1399.csv: distance filtering(before):(110358, 4)\n",
      "../data/PLdata_paju_wt_1399.csv: distance filtering(after):(22518, 4)\n",
      "          type  distance  pathloss  heightTM  season  frequency  heightTB  heightB  heightM\n",
      "type 1719    m      1.00    100.29      0.02       0        400        30       15        2\n",
      "     1720    m      1.00    124.49      0.04       0        400        30       15        2\n",
      "     1721    m      1.00     92.21      0.03       0        400        30       15        2\n",
      "     1722    m      1.00     93.33      0.01       0        400        30       15        2\n",
      "     1723    m      1.00    100.66      0.02       0        400        30       15        2\n",
      "Combined data set: (67555, 9)\n",
      "type filtering(before):(67555, 9)\n",
      "type filtering(after):(50752, 9)\n",
      "Dataframe before add new terms: (50752, 9)\n",
      "Dataframe after add constant feature: (50752, 20)\n",
      "Paju winter data: (50752, 20)\n",
      "\n",
      "ADD data preprocessing\n",
      "../data/PLdata_paju_sp_2249.csv: distance filtering(before):(90428, 4)\n",
      "../data/PLdata_paju_sp_2249.csv: distance filtering(after):(16534, 4)\n",
      "../data/PLdata_paju_sp_1399.csv: distance filtering(before):(90501, 4)\n",
      "../data/PLdata_paju_sp_1399.csv: distance filtering(after):(16534, 4)\n",
      "../data/PLdata_paju_sp_400.csv: distance filtering(before):(90557, 4)\n",
      "../data/PLdata_paju_sp_400.csv: distance filtering(after):(16534, 4)\n",
      "         type  distance  pathloss  heightTM  season  frequency  heightTB  heightB  heightM\n",
      "type 271    m      1.00     99.19      0.02    0.50       2249        30       15        2\n",
      "     272    m      1.00     99.52      0.02    0.50       2249        30       15        2\n",
      "     273    m      1.00    100.38      0.02    0.50       2249        30       15        2\n",
      "     274    m      1.00    102.94      0.02    0.50       2249        30       15        2\n",
      "     275    m      1.00    114.93      0.02    0.50       2249        30       15        2\n",
      "Combined data set: (49602, 9)\n",
      "type filtering(before):(49602, 9)\n",
      "type filtering(after):(24840, 9)\n",
      "Dataframe before add new terms: (24840, 9)\n",
      "Dataframe after add constant feature: (24840, 20)\n",
      "Paju spring data: (24840, 20)\n",
      "\n",
      "ADD data preprocessing\n",
      "../data/PLdata_paju_sm_2249.csv: distance filtering(before):(109754, 4)\n",
      "../data/PLdata_paju_sm_2249.csv: distance filtering(after):(26409, 4)\n",
      "../data/PLdata_paju_sm_1399.csv: distance filtering(before):(109891, 4)\n",
      "../data/PLdata_paju_sm_1399.csv: distance filtering(after):(26425, 4)\n",
      "../data/PLdata_paju_sm_400.csv: distance filtering(before):(109969, 4)\n",
      "../data/PLdata_paju_sm_400.csv: distance filtering(after):(26440, 4)\n",
      "         type  distance  pathloss  heightTM  season  frequency  heightTB  heightB  heightM\n",
      "type 204    m      1.02    104.12      0.02    1.00       2249       100        7        2\n",
      "     205    m      1.02    103.31      0.02    1.00       2249       100        7        2\n",
      "     206    m      1.02    106.56      0.02    1.00       2249       100        7        2\n",
      "     207    m      1.03    105.55      0.02    1.00       2249       100        7        2\n",
      "     208    m      1.03    104.04      0.02    1.00       2249       100        7        2\n",
      "Combined data set: (79274, 9)\n",
      "type filtering(before):(79274, 9)\n",
      "type filtering(after):(62336, 9)\n",
      "Dataframe before add new terms: (62336, 9)\n",
      "Dataframe after add constant feature: (62336, 20)\n",
      "Paju summer data: (62336, 20)\n",
      "\n",
      "antenna_b height filtering-before(data count): (137928, 20)\n",
      "antenna_b height filtering-after(data count): (125944, 20)\n",
      "freespace pathloss filtering-before(data count): (125944, 20)\n",
      "freespace pathloss filtering-after(data count): (123134, 20)\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "paju_wt_fileList = {'../data/PLdata_paju_wt_400.csv':[('season', 0), ('frequency', 400), ('heightTB',30), ('heightB',15), ('heightM',2)],\n",
    "            '../data/PLdata_paju_wt_1399.csv':[('season', 0), ('frequency', 1399), ('heightTB',30), ('heightB',15), ('heightM',2)],\n",
    "            '../data/PLdata_paju_wt_2249.csv':[('season', 0), ('frequency', 2249), ('heightTB',30), ('heightB',15), ('heightM',2)]}\n",
    "paju_sp_fileList = {'../data/PLdata_paju_sp_400.csv':[('season', 0.5), ('frequency', 400), ('heightTB',30), ('heightB',15), ('heightM',2)],\n",
    "            '../data/PLdata_paju_sp_1399.csv':[('season', 0.5), ('frequency', 1399), ('heightTB',30), ('heightB',15), ('heightM',2)],\n",
    "            '../data/PLdata_paju_sp_2249.csv':[('season', 0.5), ('frequency', 2249), ('heightTB',30), ('heightB',15), ('heightM',2)]}\n",
    "paju_sm_fileList = {'../data/PLdata_paju_sm_400.csv':[('season', 1.0), ('frequency', 400), ('heightTB',100), ('heightB',7), ('heightM',2)],\n",
    "            '../data/PLdata_paju_sm_1399.csv':[('season', 1.0), ('frequency', 1399), ('heightTB',100), ('heightB',7), ('heightM',2)],\n",
    "            '../data/PLdata_paju_sm_2249.csv':[('season', 1.0), ('frequency', 2249), ('heightTB',100), ('heightB',7), ('heightM',2)]}\n",
    "\n",
    "addPajuWt = ADD_data_loader(paju_wt_fileList)\n",
    "print(\"Paju winter data:\",addPajuWt.shape)\n",
    "print(\"\")\n",
    "addPajuSp = ADD_data_loader(paju_sp_fileList)\n",
    "print(\"Paju spring data:\",addPajuSp.shape)\n",
    "print(\"\")\n",
    "addPajuSm = ADD_data_loader(paju_sm_fileList)\n",
    "print(\"Paju summer data:\",addPajuSm.shape)\n",
    "print(\"\")\n",
    "\n",
    "# print(addIksan.describe())\n",
    "# print(addNonsan.describe())\n",
    "# print(addPaju.describe())\n",
    "\n",
    "addData = combineDF([addPajuWt, addPajuSp, addPajuSm])\n",
    "print(\"antenna_b height filtering-before(data count):\",addData.shape)\n",
    "addData = filteringDF(addData, 'heightTM', [10,100])\n",
    "print(\"antenna_b height filtering-after(data count):\",addData.shape)\n",
    "\n",
    "print(\"freespace pathloss filtering-before(data count):\",addData.shape)\n",
    "addData['freePathloss'] = getFreeSpacePathLoss(addData['distance'],addData['frequency'])\n",
    "addData = addData[addData['pathloss'] >= addData['freePathloss']]\n",
    "print(\"freespace pathloss filtering-after(data count):\",addData.shape)\n",
    "\n",
    "# print(\"ADD data sample:\\n\",addData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['loglogExtendedHeightTratio'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b6b56956904b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0msamplingRatio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0maddData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msamplingData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtargetCols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# addDataSample.sort_values(by=['logDistance'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2932\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2933\u001b[0m             indexer = self.loc._convert_to_indexer(key, axis=1,\n\u001b[0;32m-> 2934\u001b[0;31m                                                    raise_missing=True)\n\u001b[0m\u001b[1;32m   2935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[1;32m   1352\u001b[0m                 kwargs = {'raise_missing': True if is_setter else\n\u001b[1;32m   1353\u001b[0m                           raise_missing}\n\u001b[0;32m-> 1354\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1355\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         self._validate_read_indexer(keyarr, indexer,\n\u001b[1;32m   1160\u001b[0m                                     \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m                                     raise_missing=raise_missing)\n\u001b[0m\u001b[1;32m   1162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1250\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'loc'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1252\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} not in index\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnot_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m             \u001b[0;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['loglogExtendedHeightTratio'] not in index\""
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "targetCols = ['logDistance', 'logFrequency', 'log''logExtendedHeightTratio', 'season', 'pathloss']\n",
    "xCols = ['logDistance', 'logFrequency', 'logExtendedHeightTratio', 'season',]\n",
    "yCols = 'pathloss'\n",
    "\n",
    "samplingRatio = 0.1\n",
    "addData = samplingData(addData[targetCols], samplingRatio)\n",
    "# addDataSample.sort_values(by=['logDistance'])\n",
    "\n",
    "sc = 'manual'\n",
    "\n",
    "addDataNorm, normalizer = normalizeData(addData[targetCols], addData[yCols], scaler = sc)\n",
    "\n",
    "print(\"\\nADD data description\")\n",
    "print(addDataNorm.describe()['pathloss'])\n",
    "print(\"\\nCovariance Matrix - ADD data[Target Columns]\")\n",
    "print(\"Target Columns:\", targetCols)\n",
    "print(addDataNorm.cov()['pathloss'])\n",
    "\n",
    "print(\"\\nCorrelation Matrix - ADD data[Target Columns]\")\n",
    "print(\"Target Columns:\", targetCols)\n",
    "corrMat = addDataNorm.corr()\n",
    "print(corrMat)\n",
    "f, ax = plt.subplots(figsize=(8,7))\n",
    "sns.heatmap(corrMat, square=True)\n",
    "\n",
    "X = np.array(addDataNorm[xCols])\n",
    "Xorigin = np.array(addData[xCols]) \n",
    "Y = np.array(addData[yCols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ANN-MLP Regression train/test Error\")\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "modelList = []\n",
    "dataSet = []\n",
    "i = 1\n",
    "trainErrSum, testErrSum = 0, 0\n",
    "model = ann_mlp_regression((60,), activation='logistic', optimizer='lbfgs')\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "#     print(\"TRAIN index:\", train_index, \"TEST index:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]    \n",
    "\n",
    "    model.fit(X_train, y_train.flatten())\n",
    "    \n",
    "    pred_train = model.predict(X_train)\n",
    "    pred_test = model.predict(X_test)\n",
    "    \n",
    "    trainError = np.sqrt(mean_squared_error(y_train, pred_train))\n",
    "    testError = np.sqrt(mean_squared_error(y_test, pred_test))\n",
    "    \n",
    "    trainErrSum += trainError\n",
    "    testErrSum += testError\n",
    "    print(\"#\"+str(i)+\" Error(RMSE)-train:{} / test:{}\".format(trainError,testError)) \n",
    "    \n",
    "    dataSet.append([X_train,y_train,X_test,y_test, trainError, testError])\n",
    "    \n",
    "    filename = \"model/ann_\"+sc+\".sav\"\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "    i+=1\n",
    "i-=1\n",
    "avgTrainError, avgTestError = trainErrSum/i, testErrSum/i \n",
    "print(\"\\nAverage train error:{:.2f} | Average test error:{:.2f}\".format(avgTrainError, avgTestError))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_testSet, Y_testSet = np.zeros((X.shape)), np.zeros((1,))\n",
    "for X_train, y_train, X_test,y_test, trainError, testError in dataSet:\n",
    "    X_testSet = np.concatenate((X_testSet, X_test), axis=0)\n",
    "    Y_testSet = np.concatenate((Y_testSet, y_test), axis=0)\n",
    "\n",
    "X_testSet = np.delete(X_testSet, 0, 0)\n",
    "Y_testSet = np.delete(Y_testSet, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "model = pickle.load(open(\"model/ann_\"+sc+\".sav\", 'rb'))\n",
    "\n",
    "data = makeXforGraphWithGroupingFrequency(pd.DataFrame(X, columns=xCols),\n",
    "                     pd.DataFrame(Y, columns=['pathloss']), ['logExtendedHeightTratio', 'season'])\n",
    "\n",
    "graphX = data[0]\n",
    "graphY = data[1]\n",
    "train_2d_graph(model, normalizer, graphX, graphY, 'logDistance', \"log distance(KM)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "model = pickle.load(open(\"model/ann_\"+sc+\".sav\", 'rb'))\n",
    "\n",
    "data = makeXforGraphWithGroupingFrequency(pd.DataFrame(X, columns=xCols),\n",
    "                     pd.DataFrame(Y, columns=['pathloss']), ['logDistance', 'season'])\n",
    "\n",
    "graphX = data[0]\n",
    "graphY = data[1]\n",
    "train_2d_graph(model, normalizer, graphX, graphY, 'logExtendedHeightTratio', \"Antenna Ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "model = pickle.load(open(\"model/ann_\"+sc+\".sav\", 'rb'))\n",
    "\n",
    "data = makeXforGraphWithGroupingFrequency(pd.DataFrame(X, columns=xCols),\n",
    "                     pd.DataFrame(Y, columns=['pathloss']), ['logDistance', 'logExtendedHeightTratio'])\n",
    "\n",
    "graphX = data[0]\n",
    "graphY = data[1]\n",
    "train_2d_graph(model, normalizer, graphX, graphY, 'season', \"Season\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "i = 1\n",
    "model = pickle.load(open(\"model/ann_\"+sc+\".sav\", 'rb'))\n",
    "\n",
    "print(\"3D graph for log distance and log frequency - trainset #{}\".format(i))\n",
    "targetCols = ['logDistance', 'logFrequency']\n",
    "xLabel,yLabel,zLabel = \"log distance(KM)\",\"log frequency(Ghz)\",\"pathloss(dB)\"\n",
    "data = makeXforGraph(pd.DataFrame(X, columns=xCols),\n",
    "                     pd.DataFrame(Y, columns=['pathloss']), targetCols)\n",
    "\n",
    "graphX = data[0]\n",
    "graphY = data[1]\n",
    "train_3d_graph(model, graphX, graphY, targetCols, xLabel, yLabel, zLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "i = 1\n",
    "model = pickle.load(open(\"model/ann_\"+sc+\".sav\", 'rb'))\n",
    "\n",
    "print(\"3D graph for log distance and log antenna height B+TB/M+TM ratio - trainset #{}\".format(i))\n",
    "xLabel,yLabel,zLabel = \"log distance(KM)\",\"Antenna Height Ratio\",\"pathloss(dB)\"\n",
    "varX = ['logDistance', 'logExtendedHeightTratio']\n",
    "data = makeXforGraph(pd.DataFrame(X, columns=xCols),\n",
    "                     pd.DataFrame(Y, columns=['pathloss']), varX)\n",
    "\n",
    "graphX = data[0]\n",
    "graphY = data[1]\n",
    "train_3d_graph(model, graphX, graphY, varX, xLabel, yLabel, zLabel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "i = 1\n",
    "model = pickle.load(open(\"model/ann_\"+sc+\".sav\", 'rb'))\n",
    "\n",
    "print(\"3D graph for log distance and log antenna height B ratio - trainset #{}\".format(i))\n",
    "varX = ['logDistance', 'season', ]\n",
    "xLabel,yLabel,zLabel = \"log distance(KM)\",\"Season\",\"pathloss(dB)\"\n",
    "data = makeXforGraph(pd.DataFrame(X_testSet, columns=xCols),\n",
    "                     pd.DataFrame(Y_testSet, columns=['pathloss']), varX)\n",
    "\n",
    "graphX = data[0]\n",
    "graphY = data[1]\n",
    "train_3d_graph(model, graphX, graphY, varX, xLabel, yLabel, zLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "#logDistance  logFrequency  logHeightB  logHeightM  logExtendedHeightTratio  logHeightTratio  logAntennaMulLogDistance\n",
    "i = 1\n",
    "coefSum, interceptSum = np.array([0]*7), 0\n",
    "\n",
    "linearModel = Ridge(alpha=0.0001)\n",
    "ANNmodel = pickle.load(open(\"model/ann_\"+sc+\".sav\", 'rb'))\n",
    "\n",
    "for X_train, y_train, X_test, y_test, trainError, testError in dataSet:\n",
    "    print(\"-\"*100)\n",
    "#     X_train = scaler.inverse_transform(X_train)\n",
    "#     X_test = scaler.inverse_transform(X_test)\n",
    "    print(\"Equation Derivation for trainset #{}\".format(i))\n",
    "\n",
    "    ANNPred = ANNmodel.predict(X_train)\n",
    "    \n",
    "    linearModel.fit(X_train, ANNPred)     \n",
    "    linearPredTrain = linearModel.predict(X_train)\n",
    "    linearPredTest = linearModel.predict(X_test)\n",
    "    \n",
    "    RMSE_LIN_TRAIN = np.sqrt(mean_squared_error(linearPredTrain, y_train))\n",
    "    RMSE_LIN_TEST = np.sqrt(mean_squared_error(linearPredTest, y_test))\n",
    "    RMSE_LIN_ANN = np.sqrt(mean_squared_error(ANNPred, linearPredTrain))\n",
    "\n",
    "    print(\"ANN-Error(RMSE)-\"+str(i)+\"-train:{:6.2f}/test:{:6.2f}\".format(trainError, testError))\n",
    "    print(\"Linear-Error(RMSE)-\"+str(i)+\"-train:{:6.2f}/test:{:6.2f}\".format(RMSE_LIN_TRAIN,RMSE_LIN_TEST))\n",
    "    print(\"ANN-Linear-Error(RMSE):\", RMSE_LIN_ANN)    \n",
    "\n",
    "    print(\"\\nObjective Function\")\n",
    "    print(\"L_pathloss = {:6.2f}log_d + {:6.2f}log_f + {:6.2f}log_(h_tb + h_b/h_tm + h_m) + {:6.2f}s + {:6.2f}\"\\\n",
    "      .format(linearModel.coef_[0],linearModel.coef_[1]\n",
    "              *0.1,linearModel.coef_[2],\\\n",
    "              linearModel.coef_[3],linearModel.intercept_)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
