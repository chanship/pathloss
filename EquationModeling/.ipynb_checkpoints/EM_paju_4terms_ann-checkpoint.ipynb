{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "from equationmodel_ann import ann_mlp_regression, prediction_rmse_error, ann_linear_compare_graph, errorDist\n",
    "from util import ADD_data_loader, combineDF, filteringDF, getFreeSpacePathLoss, makeXforGraphWithGroupingFrequency,\\\n",
    "                makeXforGraph, inverseScale, samplingData, normalizeData,train_2d_graph, train_3d_graph\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "desired_width=620\n",
    "pd.set_option('display.width', desired_width)\n",
    "pd.set_option('display.max_columns',30)\n",
    "pd.options.display.float_format = \"{:.2f}\".format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADD data preprocessing\n",
      "../data/PLdata_paju_wt_400.csv: distance filtering(before):(110440, 4)\n",
      "../data/PLdata_paju_wt_400.csv: distance filtering(after):(22532, 4)\n",
      "../data/PLdata_paju_wt_1399.csv: distance filtering(before):(110358, 4)\n",
      "../data/PLdata_paju_wt_1399.csv: distance filtering(after):(22518, 4)\n",
      "../data/PLdata_paju_wt_2249.csv: distance filtering(before):(110246, 4)\n",
      "../data/PLdata_paju_wt_2249.csv: distance filtering(after):(22505, 4)\n",
      "          type  distance  pathloss  heightTM  season  frequency  heightTB  heightB  heightM\n",
      "type 1719    m      1.00    100.29      0.02       0        400       100        7        2\n",
      "     1720    m      1.00    124.49      0.04       0        400       100        7        2\n",
      "     1721    m      1.00     92.21      0.03       0        400       100        7        2\n",
      "     1722    m      1.00     93.33      0.01       0        400       100        7        2\n",
      "     1723    m      1.00    100.66      0.02       0        400       100        7        2\n",
      "Combined data set: (67555, 9)\n",
      "type filtering(before):(67555, 9)\n",
      "type filtering(after):(50752, 9)\n",
      "Dataframe before add new terms: (50752, 9)\n",
      "Dataframe after add constant feature: (50752, 20)\n",
      "winter data: (50752, 20)\n",
      "\n",
      "ADD data preprocessing\n",
      "../data/PLdata_paju_sp_1399.csv: distance filtering(before):(90501, 4)\n",
      "../data/PLdata_paju_sp_1399.csv: distance filtering(after):(16534, 4)\n",
      "../data/PLdata_paju_sp_400.csv: distance filtering(before):(90557, 4)\n",
      "../data/PLdata_paju_sp_400.csv: distance filtering(after):(16534, 4)\n",
      "../data/PLdata_paju_sp_2249.csv: distance filtering(before):(90428, 4)\n",
      "../data/PLdata_paju_sp_2249.csv: distance filtering(after):(16534, 4)\n",
      "         type  distance  pathloss  heightTM  season  frequency  heightTB  heightB  heightM\n",
      "type 297    m      1.00    101.38      0.02    0.50       1399       100        7        2\n",
      "     298    m      1.00    100.69      0.02    0.50       1399       100        7        2\n",
      "     299    m      1.00     98.91      0.02    0.50       1399       100        7        2\n",
      "     300    m      1.00    104.47      0.02    0.50       1399       100        7        2\n",
      "     301    m      1.01    112.83      0.02    0.50       1399       100        7        2\n",
      "Combined data set: (49602, 9)\n",
      "type filtering(before):(49602, 9)\n",
      "type filtering(after):(24840, 9)\n",
      "Dataframe before add new terms: (24840, 9)\n",
      "Dataframe after add constant feature: (24840, 20)\n",
      "spring data: (24840, 20)\n",
      "\n",
      "ADD data preprocessing\n",
      "../data/PLdata_paju_sm_1399.csv: distance filtering(before):(109891, 4)\n",
      "../data/PLdata_paju_sm_1399.csv: distance filtering(after):(26425, 4)\n",
      "../data/PLdata_paju_sm_400.csv: distance filtering(before):(109969, 4)\n",
      "../data/PLdata_paju_sm_400.csv: distance filtering(after):(26440, 4)\n",
      "../data/PLdata_paju_sm_2249.csv: distance filtering(before):(109754, 4)\n",
      "../data/PLdata_paju_sm_2249.csv: distance filtering(after):(26409, 4)\n",
      "         type  distance  pathloss  heightTM  season  frequency  heightTB  heightB  heightM\n",
      "type 275    m      1.02    109.31      0.02    1.00       1399       100        7        2\n",
      "     276    m      1.02    115.94      0.02    1.00       1399       100        7        2\n",
      "     277    m      1.03    109.14      0.02    1.00       1399       100        7        2\n",
      "     278    m      1.03    107.74      0.02    1.00       1399       100        7        2\n",
      "     279    s      1.04    104.94      0.02    1.00       1399       100        7        2\n",
      "Combined data set: (79274, 9)\n",
      "type filtering(before):(79274, 9)\n",
      "type filtering(after):(62336, 9)\n",
      "Dataframe before add new terms: (62336, 9)\n",
      "Dataframe after add constant feature: (62336, 20)\n",
      "summer data: (62336, 20)\n",
      "\n",
      "antenna_b height filtering-before(data count): (137928, 20)\n",
      "antenna_b height filtering-after(data count): (125944, 20)\n",
      "freespace pathloss filtering-before(data count): (125944, 20)\n",
      "freespace pathloss filtering-after(data count): (123134, 20)\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "wt_fileList = {'../data/PLdata_paju_wt_400.csv':[('season', 0), ('frequency', 400), ('heightTB',100), ('heightB',7), ('heightM',2)],\n",
    "            '../data/PLdata_paju_wt_1399.csv':[('season', 0), ('frequency', 1399), ('heightTB',100), ('heightB',7), ('heightM',2)],\n",
    "            '../data/PLdata_paju_wt_2249.csv':[('season', 0), ('frequency', 2249), ('heightTB',100), ('heightB',7), ('heightM',2)]}\n",
    "sp_fileList = {'../data/PLdata_paju_sp_400.csv':[('season', 0.5), ('frequency', 400), ('heightTB',100), ('heightB',7), ('heightM',2)],\n",
    "            '../data/PLdata_paju_sp_1399.csv':[('season', 0.5), ('frequency', 1399), ('heightTB',100), ('heightB',7), ('heightM',2)],\n",
    "            '../data/PLdata_paju_sp_2249.csv':[('season', 0.5), ('frequency', 2249), ('heightTB',100), ('heightB',7), ('heightM',2)]}\n",
    "sm_fileList = {'../data/PLdata_paju_sm_400.csv':[('season', 1.0), ('frequency', 400), ('heightTB',100), ('heightB',7), ('heightM',2)],\n",
    "            '../data/PLdata_paju_sm_1399.csv':[('season', 1.0), ('frequency', 1399), ('heightTB',100), ('heightB',7), ('heightM',2)],\n",
    "            '../data/PLdata_paju_sm_2249.csv':[('season', 1.0), ('frequency', 2249), ('heightTB',100), ('heightB',7), ('heightM',2)]}\n",
    "addWt = ADD_data_loader(wt_fileList)\n",
    "print(\"winter data:\",addWt.shape)\n",
    "print(\"\")\n",
    "addSp = ADD_data_loader(sp_fileList)\n",
    "print(\"spring data:\",addSp.shape)\n",
    "print(\"\")\n",
    "addSm = ADD_data_loader(sm_fileList)\n",
    "print(\"summer data:\",addSm.shape)\n",
    "print(\"\")\n",
    "\n",
    "# print(addIksan.describe())\n",
    "# print(addNonsan.describe())\n",
    "# print(addPaju.describe())\n",
    "\n",
    "addData = combineDF([addWt, addSp, addSm])\n",
    "print(\"antenna_b height filtering-before(data count):\",addData.shape)\n",
    "addData = filteringDF(addData, 'heightTM', [10,100])\n",
    "print(\"antenna_b height filtering-after(data count):\",addData.shape)\n",
    "\n",
    "print(\"freespace pathloss filtering-before(data count):\",addData.shape)\n",
    "addData['freePathloss'] = getFreeSpacePathLoss(addData['distance'],addData['frequency'])\n",
    "addData = addData[addData['pathloss'] >= addData['freePathloss']]\n",
    "print(\"freespace pathloss filtering-after(data count):\",addData.shape)\n",
    "\n",
    "# print(\"ADD data sample:\\n\",addData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data distribution(before)\n",
      "       logDistance  logFrequency  logExtendedHeightTratio    season  pathloss\n",
      "count    123134.00     123134.00                123134.00 123134.00 123134.00\n",
      "mean          0.39          3.04                     0.64      0.54    127.74\n",
      "std           0.16          0.31                     0.18      0.45     14.12\n",
      "min           0.00          2.60                     0.02      0.00     85.47\n",
      "25%           0.28          2.60                     0.51      0.00    117.05\n",
      "50%           0.41          3.15                     0.66      0.50    128.39\n",
      "75%           0.52          3.35                     0.78      1.00    138.74\n",
      "max           0.60          3.35                     0.95      1.00    171.41\n",
      "sampling shape(before):(123134, 5)\n",
      "sampling shape(after):(36940, 5)\n",
      "data distribution(after)\n",
      "       logDistance  logFrequency  logExtendedHeightTratio   season  pathloss\n",
      "count     36940.00      36940.00                 36940.00 36940.00  36940.00\n",
      "mean          0.39          3.04                     0.64     0.54    127.73\n",
      "std           0.16          0.31                     0.18     0.45     14.14\n",
      "min           0.00          2.60                     0.02     0.00     85.51\n",
      "25%           0.28          2.60                     0.51     0.00    117.06\n",
      "50%           0.41          3.15                     0.66     0.50    128.22\n",
      "75%           0.52          3.35                     0.78     1.00    138.76\n",
      "max           0.60          3.35                     0.95     1.00    167.46\n",
      "normalization distribution(before):\n",
      "       logDistance  logFrequency  logExtendedHeightTratio   season\n",
      "count     36940.00      36940.00                 36940.00 36940.00\n",
      "mean          0.39          3.04                     0.64     0.54\n",
      "std           0.16          0.31                     0.18     0.45\n",
      "min           0.00          2.60                     0.02     0.00\n",
      "25%           0.28          2.60                     0.51     0.00\n",
      "50%           0.41          3.15                     0.66     0.50\n",
      "75%           0.52          3.35                     0.78     1.00\n",
      "max           0.60          3.35                     0.95     1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py:2880: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  return runner(coro)\n",
      "/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py:635: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalization distribution(after):\n",
      "       logDistance  logFrequency  logExtendedHeightTratio   season\n",
      "count     36940.00      36940.00                 36940.00 36940.00\n",
      "mean          0.39          0.30                     0.64     0.54\n",
      "std           0.16          0.03                     0.18     0.45\n",
      "min           0.00          0.26                     0.02     0.00\n",
      "25%           0.28          0.26                     0.51     0.00\n",
      "50%           0.41          0.31                     0.66     0.50\n",
      "75%           0.52          0.34                     0.78     1.00\n",
      "max           0.60          0.34                     0.95     1.00\n",
      "\n",
      "ADD data description\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'pathloss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2656\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2657\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'pathloss'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a04616e576da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nADD data description\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddDataNorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pathloss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nCovariance Matrix - ADD data[Target Columns]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target Columns:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargetCols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2927\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2657\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'pathloss'"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "targetCols = ['logDistance', 'logFrequency', 'logExtendedHeightTratio', 'season', 'pathloss']\n",
    "xCols = ['logDistance', 'logFrequency', 'logExtendedHeightTratio', 'season',]\n",
    "yCols = 'pathloss'\n",
    "\n",
    "sampleRatio = 0.3\n",
    "addDataSampled = samplingData(addData[targetCols], sampleRatio, None)\n",
    "# addDataSample.sort_values(by=['logDistance'])\n",
    "\n",
    "sc = 'paju_4term'\n",
    "scale = 'manual'\n",
    "\n",
    "addDataNorm, normalizer = normalizeData(addDataSampled[targetCols], addDataSampled[yCols], scaler = scale)\n",
    "\n",
    "print(\"\\nADD data description\")\n",
    "print(addDataNorm.describe()['pathloss'])\n",
    "print(\"\\nCovariance Matrix - ADD data[Target Columns]\")\n",
    "print(\"Target Columns:\", targetCols)\n",
    "print(addDataNorm.cov()['pathloss'])\n",
    "\n",
    "print(\"\\nCorrelation Matrix - ADD data[Target Columns]\")\n",
    "print(\"Target Columns:\", targetCols)\n",
    "corrMat = addDataNorm.corr()\n",
    "print(corrMat)\n",
    "f, ax = plt.subplots(figsize=(8,7))\n",
    "sns.heatmap(corrMat, square=True)\n",
    "\n",
    "X = np.array(addDataNorm[xCols])\n",
    "Xorigin = np.array(addData[xCols]) \n",
    "Y = np.array(addDataNorm[yCols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ANN-MLP Regression train/test Error\")\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "bestANNModel = None\n",
    "bestIdx = 0\n",
    "modelList = []\n",
    "dataSet = []\n",
    "i = 1\n",
    "prevTestError = 0\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "#     print(\"TRAIN index:\", train_index, \"TEST index:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]    \n",
    "    \n",
    "    model = ann_mlp_regression((60,), activation='logistic', optimizer='lbfgs')\n",
    "    model.fit(X_train, y_train.flatten())\n",
    "    \n",
    "    pred_train = model.predict(X_train)\n",
    "    pred_test = model.predict(X_test)\n",
    "    \n",
    "    trainError = np.sqrt(mean_squared_error(y_train, pred_train))\n",
    "    testError = np.sqrt(mean_squared_error(y_test, pred_test))\n",
    "    \n",
    "    print(\"#\"+str(i)+\" Error(RMSE)-train:{} / test:{}\".format(trainError,testError)) \n",
    "    \n",
    "    dataSet.append([X_train,y_train,X_test,y_test, trainError, testError])\n",
    "    \n",
    "    filename = 'model/ann_'+sc+'-'+str(i)+'.sav'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    \n",
    "    if i == 1:\n",
    "        prevTestError = testError\n",
    "        bestANNModel = model\n",
    "        bestIdx = i\n",
    "    if prevTestError > testError:\n",
    "        bestANNModel = model\n",
    "        bestIdx = i\n",
    "        prevTestError = testError\n",
    "    \n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "data = makeXforGraphWithGroupingFrequency(pd.DataFrame(X, columns=xCols),\n",
    "                     pd.DataFrame(Y, columns=['pathloss']), ['logExtendedHeightTratio', 'season'])\n",
    "\n",
    "graphX = data[0]\n",
    "graphY = data[1]\n",
    "train_2d_graph(bestANNModel, None, None, graphX, graphY, 'logDistance', \"log distance(KM)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "data = makeXforGraphWithGroupingFrequency(pd.DataFrame(X, columns=xCols),\n",
    "                     pd.DataFrame(Y, columns=['pathloss']), ['logDistance', 'season'])\n",
    "\n",
    "graphX = data[0]\n",
    "graphY = data[1]\n",
    "train_2d_graph(bestANNModel, None, None, graphX, graphY, 'logExtendedHeightTratio', \"Antenna Ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "data = makeXforGraphWithGroupingFrequency(pd.DataFrame(X, columns=xCols),\n",
    "                     pd.DataFrame(Y, columns=['pathloss']), ['logDistance', 'logExtendedHeightTratio'])\n",
    "\n",
    "graphX = data[0]\n",
    "graphY = data[1]\n",
    "train_2d_graph(bestANNModel, None, None,graphX, graphY, 'season', \"Season\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "i = 1\n",
    "print(\"3D graph for log distance and log frequency - trainset #{}\".format(i))\n",
    "targetCols = ['logDistance', 'logFrequency']\n",
    "xLabel,yLabel,zLabel = \"log distance(KM)\",\"log frequency(Ghz)\",\"pathloss(dB)\"\n",
    "data = makeXforGraph(pd.DataFrame(X, columns=xCols),\n",
    "                     pd.DataFrame(Y, columns=['pathloss']), targetCols)\n",
    "\n",
    "graphX = data[0]\n",
    "graphY = data[1]\n",
    "train_3d_graph(bestANNModel, graphX, graphY, targetCols, xLabel, yLabel, zLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "print(\"3D graph for log distance and log antenna height B+TB/M+TM ratio - trainset #{}\".format(i))\n",
    "xLabel,yLabel,zLabel = \"log distance(KM)\",\"Antenna Height Ratio\",\"pathloss(dB)\"\n",
    "varX = ['logDistance', 'logExtendedHeightTratio']\n",
    "data = makeXforGraph(pd.DataFrame(X, columns=xCols),\n",
    "                     pd.DataFrame(Y, columns=['pathloss']), varX)\n",
    "\n",
    "graphX = data[0]\n",
    "graphY = data[1]\n",
    "train_3d_graph(bestANNModel, graphX, graphY, varX, xLabel, yLabel, zLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "print(\"3D graph for log distance and log antenna height B ratio - trainset #{}\".format(i))\n",
    "varX = ['logDistance', 'season', ]\n",
    "xLabel,yLabel,zLabel = \"log distance(KM)\",\"Season\",\"pathloss(dB)\"\n",
    "data = makeXforGraph(pd.DataFrame(X, columns=xCols),\n",
    "                     pd.DataFrame(Y, columns=['pathloss']), varX)\n",
    "\n",
    "graphX = data[0]\n",
    "graphY = data[1]\n",
    "train_3d_graph(bestANNModel, graphX, graphY, varX, xLabel, yLabel, zLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "#logDistance  logFrequency  logHeightB  logHeightM  logExtendedHeightTratio  logHeightTratio  logAntennaMulLogDistance\n",
    "i = 1\n",
    "bestLinearModel = None\n",
    "bestIdx = 0\n",
    "bestStat = None\n",
    "prevTestError = 0\n",
    "\n",
    "for X_train, y_train, X_test, y_test, trainError, testError in dataSet:\n",
    "    print(\"-\"*100)\n",
    "#     X_train = scaler.inverse_transform(X_train)\n",
    "#     X_test = scaler.inverse_transform(X_test)\n",
    "    print(\"Equation Derivation for trainset #{}\".format(i))\n",
    "\n",
    "    ANNPred = bestANNModel.predict(X_train)\n",
    "    ANNPred_test = bestANNModel.predict(X_test)  \n",
    "    linearModel = Ridge(alpha=0.0001)\n",
    "    linearModel.fit(X_train, ANNPred)     \n",
    "    linearPredTrain = linearModel.predict(X_train)\n",
    "    linearPredTest = linearModel.predict(X_test)\n",
    "    \n",
    "    RMSE_ANN_TRAIN = np.sqrt(mean_squared_error(y_train, ANNPred))\n",
    "    RMSE_ANN_TEST = np.sqrt(mean_squared_error(y_test, ANNPred_test))\n",
    "    RMSE_LIN_TRAIN = np.sqrt(mean_squared_error(y_train, linearPredTrain))\n",
    "    RMSE_LIN_TEST = np.sqrt(mean_squared_error(y_test, linearPredTest))\n",
    "    RMSE_LIN_ANN = np.sqrt(mean_squared_error(ANNPred, linearPredTrain))\n",
    "    errorDist(ANNPred, linearPredTrain)    \n",
    "    stat = np.array([RMSE_ANN_TRAIN, mean_absolute_error(y_train, ANNPred),mean_absolute_percentage_error(y_train, ANNPred),np.sqrt(mean_squared_log_error(y_train, ANNPred)),r2_score(y_train, ANNPred),\\\n",
    "                    RMSE_ANN_TEST, mean_absolute_error(y_test, ANNPred_test),mean_absolute_percentage_error(y_test, ANNPred_test),np.sqrt(mean_squared_log_error(y_test, ANNPred_test)),r2_score(y_test, ANNPred_test),\\\n",
    "                    RMSE_LIN_TRAIN, mean_absolute_error(y_train, linearPredTrain),mean_absolute_percentage_error(y_train, linearPredTrain),np.sqrt(mean_squared_log_error(y_train, linearPredTrain)),r2_score(y_train, linearPredTrain),\\\n",
    "                    RMSE_LIN_TEST, mean_absolute_error(y_test, linearPredTest),mean_absolute_percentage_error(y_test, linearPredTest), np.sqrt(mean_squared_log_error(y_test, linearPredTest)),r2_score(y_test, linearPredTest),\\\n",
    "                    RMSE_LIN_ANN, mean_absolute_error(ANNPred, linearPredTrain),mean_absolute_percentage_error(ANNPred, linearPredTrain), np.sqrt(mean_squared_log_error(ANNPred, linearPredTrain)),r2_score(ANNPred, linearPredTrain)])\n",
    "\n",
    "    print(pd.DataFrame(stat.reshape((5,5)),index=pd.Index(['ANN Train','ANN Test','Linear Train','Linear Test','Diff(ANN,Linear)']), columns=pd.Index(['RMSE','MAE','MAPE','RMSLE','R2'],name='TEST ERROR(dB)')))\n",
    "\n",
    "    print(\"\\nObjective Function\")\n",
    "    print(\"L_pathloss = {:6.2f}log_d + {:6.2f}log_f + {:6.2f}|log_(hb1/hm1)| + {:6.2f}s + {:6.2f}\"\\\n",
    "      .format(linearModel.coef_[0],linearModel.coef_[1]\n",
    "              *0.1,linearModel.coef_[2],\\\n",
    "              linearModel.coef_[3],linearModel.intercept_)) \n",
    "    if i == 1:\n",
    "        prevTestError = RMSE_LIN_TEST\n",
    "        bestLinearModel = linearModel\n",
    "        bestIdx = i\n",
    "        bestStat = stat\n",
    "    if prevTestError < RMSE_LIN_TEST:\n",
    "        bestLinearModel = linearModel\n",
    "        bestIdx = i\n",
    "        bestStat = stat\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "print(\"best model:\")\n",
    "print(\"L_pathloss = {:6.2f}log_d + {:6.2f}log_f + {:6.2f}|log_(hb1/hm1)| + {:6.2f}s + {:6.2f}\"\\\n",
    "      .format(bestLinearModel.coef_[0],bestLinearModel.coef_[1]\n",
    "              *0.1,bestLinearModel.coef_[2],\\\n",
    "              bestLinearModel.coef_[3],bestLinearModel.intercept_))\n",
    "statDf = pd.DataFrame(bestStat.reshape((5,5)),index=pd.Index(['ANN Train','ANN Test','Linear Train','Linear Test','Diff(ANN,Linear)']), columns=pd.Index(['RMSE','MAE','MAPE','RMSLE','R2'],name='TEST ERROR(dB)'))\n",
    "print(statDf)\n",
    "statDf.to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = makeXforGraphWithGroupingFrequency(pd.DataFrame(X, columns=xCols),\n",
    "                     pd.DataFrame(Y, columns=['pathloss']), ['logExtendedHeightTratio', 'season'])\n",
    "\n",
    "graphX = data[0]\n",
    "graphY = data[1]\n",
    "train_2d_graph(bestANNModel, bestLinearModel, True, graphX, graphY, 'logDistance', \"log distance(KM)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "data = makeXforGraphWithGroupingFrequency(pd.DataFrame(X, columns=xCols),\n",
    "                     pd.DataFrame(Y, columns=['pathloss']), ['logDistance', 'season'])\n",
    "\n",
    "graphX = data[0]\n",
    "graphY = data[1]\n",
    "train_2d_graph(bestANNModel, bestLinearModel, None, graphX, graphY, 'logExtendedHeightTratio', \"Antenna Ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "data = makeXforGraphWithGroupingFrequency(pd.DataFrame(X, columns=xCols),\n",
    "                     pd.DataFrame(Y, columns=['pathloss']), ['logDistance', 'logExtendedHeightTratio'])\n",
    "\n",
    "graphX = data[0]\n",
    "graphY = data[1]\n",
    "train_2d_graph(bestANNModel, bestLinearModel, None, graphX, graphY, 'season', \"Season\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "i = 1\n",
    "print(\"3D graph for log distance and log frequency - trainset #{}\".format(i))\n",
    "targetCols = ['logDistance', 'logFrequency']\n",
    "xLabel,yLabel,zLabel = \"log distance(KM)\",\"log frequency(Ghz)\",\"pathloss(dB)\"\n",
    "data = makeXforGraph(pd.DataFrame(X, columns=xCols),\n",
    "                     pd.DataFrame(Y, columns=['pathloss']), targetCols)\n",
    "\n",
    "graphX = data[0]\n",
    "graphY = data[1]\n",
    "train_3d_graph(bestLinearModel, graphX, graphY, targetCols, xLabel, yLabel, zLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "print(\"3D graph for log distance and log antenna height B+TB/M+TM ratio - trainset #{}\".format(i))\n",
    "xLabel,yLabel,zLabel = \"log distance(KM)\",\"Antenna Height Ratio\",\"pathloss(dB)\"\n",
    "varX = ['logDistance', 'logExtendedHeightTratio']\n",
    "data = makeXforGraph(pd.DataFrame(X, columns=xCols),\n",
    "                     pd.DataFrame(Y, columns=['pathloss']), varX)\n",
    "\n",
    "graphX = data[0]\n",
    "graphY = data[1]\n",
    "train_3d_graph(bestLinearModel, graphX, graphY, varX, xLabel, yLabel, zLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "print(\"3D graph for log distance and log antenna height B ratio - trainset #{}\".format(i))\n",
    "varX = ['logDistance', 'season', ]\n",
    "xLabel,yLabel,zLabel = \"log distance(KM)\",\"Season\",\"pathloss(dB)\"\n",
    "data = makeXforGraph(pd.DataFrame(X, columns=xCols),\n",
    "                     pd.DataFrame(Y, columns=['pathloss']), varX)\n",
    "\n",
    "graphX = data[0]\n",
    "graphY = data[1]\n",
    "train_3d_graph(bestLinearModel, graphX, graphY, varX, xLabel, yLabel, zLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
